{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import random as rand\n",
    "import time\n",
    "rand.seed(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "raw_data = list()\n",
    "with open(\"(Optimization, AICS301)Lecture 07 Example of Backpropagation.csv\",'r',encoding='utf-8-sig') as file:\n",
    "    for line in csv.reader(file):\n",
    "        raw_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for read file and transform\n",
    "def data_processing(index):\n",
    "    data = np.zeros((4,3),dtype=int)\n",
    "    c_i = 0\n",
    "    for _i in range(data.shape[0]):\n",
    "        r_i = 0\n",
    "        for _j in range(data.shape[1]):\n",
    "            temp = raw_data[_i+1][index*4 + _j]\n",
    "            #print(\"row\", r_i + 1, \"col\", c_i + 1, \"val\", temp)\n",
    "            temp = np.array(temp)\n",
    "            temp = temp.astype(np.float64)\n",
    "            data[c_i][r_i] = temp\n",
    "            r_i = r_i + 1\n",
    "        #print()\n",
    "        c_i = c_i + 1\n",
    "    label = int(raw_data[5][index*4 + 3])\n",
    "\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for print matrix in fixed format\n",
    "def print_matrix(ann = None, x = None, y = None):\n",
    "    print()\n",
    "    print(ann)\n",
    "    if y is None:\n",
    "        if type(x) == \"ndarray\":\n",
    "            for _i in range(x.shape[0]):\n",
    "                print(\"ndarray\")\n",
    "                pass\n",
    "        for _i in range(len(x)):\n",
    "            print(_i+1, x[_i])\n",
    "    else:\n",
    "        for _i in range(x.shape[0]):\n",
    "            print(_i+1, \"\\n\", x[_i], \"\\nLabel:\", y[_i], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = list()\n",
    "label = list()\n",
    "for _i in range(64):\n",
    "    datas.append(data_processing(_i)[0])\n",
    "    label.append(data_processing(_i)[1])\n",
    "datas = np.array(datas)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data & label\n",
      "1 \n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "2 \n",
      " [[0 1 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "3 \n",
      " [[1 1 0]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "4 \n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 1 0]] \n",
      "Label: 0 \n",
      "\n",
      "5 \n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [0 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "6 \n",
      " [[0 0 0]\n",
      " [1 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "7 \n",
      " [[0 0 0]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "8 \n",
      " [[0 0 0]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "9 \n",
      " [[0 0 0]\n",
      " [1 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]] \n",
      "Label: 0 \n",
      "\n",
      "10 \n",
      " [[0 0 0]\n",
      " [1 1 1]\n",
      " [1 0 1]\n",
      " [0 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "11 \n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]\n",
      " [0 0 0]] \n",
      "Label: 0 \n",
      "\n",
      "12 \n",
      " [[0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]\n",
      " [0 0 0]] \n",
      "Label: 0 \n",
      "\n",
      "13 \n",
      " [[1 1 0]\n",
      " [1 0 1]\n",
      " [1 1 1]\n",
      " [0 0 0]] \n",
      "Label: 0 \n",
      "\n",
      "14 \n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [0 0 0]] \n",
      "Label: 0 \n",
      "\n",
      "15 \n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [0 1 1]\n",
      " [0 0 0]] \n",
      "Label: 0 \n",
      "\n",
      "16 \n",
      " [[1 0 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "17 \n",
      " [[1 1 1]\n",
      " [1 0 0]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "18 \n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 0]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "19 \n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 0 1]] \n",
      "Label: 0 \n",
      "\n",
      "20 \n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "21 \n",
      " [[1 1 1]\n",
      " [0 0 1]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "22 \n",
      " [[0 0 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "23 \n",
      " [[0 1 1]\n",
      " [1 0 0]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "24 \n",
      " [[0 1 1]\n",
      " [1 0 1]\n",
      " [1 0 0]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "25 \n",
      " [[0 1 1]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 0 1]] \n",
      "Label: 0 \n",
      "\n",
      "26 \n",
      " [[0 1 1]\n",
      " [1 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "27 \n",
      " [[0 1 1]\n",
      " [0 0 1]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "28 \n",
      " [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "29 \n",
      " [[1 1 0]\n",
      " [1 0 1]\n",
      " [1 0 0]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "30 \n",
      " [[1 1 0]\n",
      " [1 0 1]\n",
      " [1 0 1]\n",
      " [1 0 1]] \n",
      "Label: 0 \n",
      "\n",
      "31 \n",
      " [[1 1 0]\n",
      " [1 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "32 \n",
      " [[1 1 0]\n",
      " [0 0 1]\n",
      " [1 0 1]\n",
      " [1 1 1]] \n",
      "Label: 0 \n",
      "\n",
      "33 \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "34 \n",
      " [[1 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "35 \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "36 \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "37 \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 1]] \n",
      "Label: 1 \n",
      "\n",
      "38 \n",
      " [[1 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "39 \n",
      " [[1 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 1]] \n",
      "Label: 1 \n",
      "\n",
      "40 \n",
      " [[1 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 1 1]] \n",
      "Label: 1 \n",
      "\n",
      "41 \n",
      " [[0 1 0]\n",
      " [0 1 1]\n",
      " [0 1 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "42 \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 1]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "43 \n",
      " [[1 1 0]\n",
      " [0 1 1]\n",
      " [0 1 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "44 \n",
      " [[1 1 0]\n",
      " [0 1 0]\n",
      " [0 1 1]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "45 \n",
      " [[0 1 0]\n",
      " [0 1 1]\n",
      " [0 1 0]\n",
      " [1 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "46 \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 1]\n",
      " [1 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "47 \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 1 1]] \n",
      "Label: 1 \n",
      "\n",
      "48 \n",
      " [[1 1 0]\n",
      " [0 1 1]\n",
      " [0 1 1]\n",
      " [0 1 1]] \n",
      "Label: 1 \n",
      "\n",
      "49 \n",
      " [[1 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "50 \n",
      " [[0 1 1]\n",
      " [0 1 1]\n",
      " [0 1 1]\n",
      " [0 1 1]] \n",
      "Label: 1 \n",
      "\n",
      "51 \n",
      " [[1 1 0]\n",
      " [1 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "52 \n",
      " [[1 1 0]\n",
      " [0 1 0]\n",
      " [1 1 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "53 \n",
      " [[1 1 0]\n",
      " [1 1 0]\n",
      " [1 1 0]\n",
      " [1 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "54 \n",
      " [[1 1 0]\n",
      " [0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "55 \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]] \n",
      "Label: 1 \n",
      "\n",
      "56 \n",
      " [[1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "57 \n",
      " [[1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]] \n",
      "Label: 1 \n",
      "\n",
      "58 \n",
      " [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 0]\n",
      " [1 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "59 \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 0]\n",
      " [1 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "60 \n",
      " [[0 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "61 \n",
      " [[0 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "62 \n",
      " [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 0]] \n",
      "Label: 1 \n",
      "\n",
      "63 \n",
      " [[0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n",
      "64 \n",
      " [[0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]] \n",
      "Label: 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_matrix(\"Data & label\", datas, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset index: [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63]\n",
      "Test dataset index: [8, 14, 33, 36, 38, 56]\n"
     ]
    }
   ],
   "source": [
    "n_data = len(datas) #number of data\n",
    "n_layer = 1 #number of hidden layer\n",
    "n_node = 3 #number of hidden node\n",
    "n_out = 2 #number of output layer node\n",
    "epoch = 50 #number of epoch\n",
    "learningrate = 0.2 #learning rate\n",
    "\n",
    "ratio = 0.1\n",
    "n_test = int(n_data * ratio) #number of test dataset\n",
    "n_train = n_data - n_test #number of train dataset\n",
    "TRAIN_INDEX = list()\n",
    "TEST_INDEX = list()\n",
    "if n_train == n_data:\n",
    "            TRAIN_INDEX = range(n_data)\n",
    "else:\n",
    "    while len(TRAIN_INDEX) < n_train:\n",
    "        temp = rand.randint(0, n_data - 1)\n",
    "        while temp in TRAIN_INDEX:\n",
    "            temp = rand.randint(0, n_data - 1)\n",
    "        TRAIN_INDEX.append(temp)\n",
    "    TRAIN_INDEX.sort()\n",
    "\n",
    "for _i in range(n_data):\n",
    "    if _i not in TRAIN_INDEX:\n",
    "        TEST_INDEX.append(_i)\n",
    "\n",
    "print(\"Test dataset index:\", TRAIN_INDEX)\n",
    "print(\"Test dataset index:\", TEST_INDEX)\n",
    "\n",
    "d_height = datas[0].shape[0]\n",
    "d_width = datas[0].shape[1]\n",
    "\n",
    "INIT_FLAG = False\n",
    "DEBUG = False\n",
    "CLEAN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return round((1 / (1 + np.exp(-x))), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute differential of sigmoid\n",
    "def d_sigmoid(x):\n",
    "    return round(x-x**2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute (data) * (weight) + bias\n",
    "def accumulate(x:np.array, y:np.array, b):\n",
    "    sum = 0\n",
    "    temp = x*y\n",
    "    sum = temp.sum() + b\n",
    "    return round(sum, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return answer label for class\n",
    "def answer(x):\n",
    "    if x == 0:\n",
    "        return np.array([1, 0])\n",
    "    else:\n",
    "        return np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class param():\n",
    "    def __init__(self, learningrate):\n",
    "        self.lr = learningrate\n",
    "\n",
    "    def init(self):\n",
    "        if not CLEAN:\n",
    "            print(\"Initialize setting\")\n",
    "        \n",
    "    #Initialize weight\n",
    "    def initialize(self, width, height = 1):\n",
    "        weight = list()\n",
    "        for _i in range(height):\n",
    "            temp = list()\n",
    "            for _j in range(width):\n",
    "                temp.append(round(norm.ppf(rand.random()), 3))\n",
    "\n",
    "            temp = np.array(temp)\n",
    "            temp = temp.astype(np.float64)\n",
    "            weight.append(temp)\n",
    "        weight = np.array(weight)\n",
    "        return weight\n",
    "    \n",
    "    #Update weight\n",
    "    def update(self, width, height = 1, weight=None, backprop=None):\n",
    "        if INIT_FLAG:#Implementation for set initial weight\n",
    "            return self.initialize(width, height)\n",
    "            pass\n",
    "        else: #Implementation for update weight\n",
    "            #w_prev - learingrate * backpropagation_hidden_layer\n",
    "            new_weight = list()\n",
    "            if DEBUG:\n",
    "                print_matrix(\"\\nprevious weight\", weight)\n",
    "                print_matrix(\"\\nbackpropagation\", backprop)\n",
    "            for _i in range(height):\n",
    "                update_temp = list()\n",
    "                for _j in range(width):\n",
    "                    update_temp.append(round(float(weight[_i][_j] - self.lr * backprop[_i][_j]), 3))\n",
    "                new_weight.append(update_temp)\n",
    "            new_weight = np.array(new_weight)\n",
    "            return new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class set_node_param:\n",
    "    def __init__(self, weight_n, bias_n, weight_o, bias_o):\n",
    "        self._z2 = list()\n",
    "        self._a2 = list()\n",
    "        self._da2 = list()\n",
    "        self._z3 = list()\n",
    "        self._a3 = list()\n",
    "        self._da3 = list()\n",
    "        self._ca3 = list()\n",
    "        self._d3 = list()\n",
    "        self._swd3 = list()\n",
    "        #d2\n",
    "        \n",
    "        self._weight_n = weight_n\n",
    "        self._bias_n = bias_n\n",
    "        self._weight_o = weight_o\n",
    "        self._bias_o = bias_o\n",
    "        \n",
    "    def z2_gen(self, index):\n",
    "        z2 = list()\n",
    "        for _i in range(n_node):\n",
    "            z2.append(accumulate(datas[index], self._weight_n[_i], self._bias_n[_i]))\n",
    "        self._z2 = z2.copy()\n",
    "        if DEBUG:\n",
    "            print_matrix(\"\\nz2 values\", z2)\n",
    "        return z2\n",
    "    \n",
    "    def a2_gen(self):\n",
    "        a2 = list()\n",
    "        for _i in range(n_node):\n",
    "            a2.append(sigmoid(self._z2[_i]))\n",
    "        a2 = np.array(a2)\n",
    "        self._a2 = a2.copy()\n",
    "        if DEBUG:\n",
    "            print_matrix(\"\\na2 values\", self._a2)\n",
    "        return a2\n",
    "    \n",
    "    def da2_gen(self):\n",
    "        da2 = list()\n",
    "        for _i in range(n_node):\n",
    "            da2.append(d_sigmoid(self._a2[_i]))\n",
    "        da2 = np.array(da2)\n",
    "        self._da2 = da2.copy()\n",
    "        if DEBUG:\n",
    "            print_matrix(\"\\ndifferential of a2 values\", self._da2)\n",
    "        return da2\n",
    "    \n",
    "    def z3_gen(self):\n",
    "        z3 = list()\n",
    "        for _i in range(n_out):\n",
    "            z3.append(accumulate(self._weight_o[_i], self._a2, self._bias_o[_i]))\n",
    "        z3 = np.array(z3)\n",
    "        self._z3 = z3.copy()\n",
    "        if DEBUG:\n",
    "            print_matrix(\"\\nz3 values\", self._z3)\n",
    "        return z3\n",
    "        \n",
    "    def a3_gen(self):\n",
    "        a3 = list()\n",
    "        for _i in range(n_out):\n",
    "            a3.append(sigmoid(self._z3[_i]))\n",
    "        a3 = np.array(a3)\n",
    "        self._a3 = a3.copy()\n",
    "        if DEBUG:\n",
    "            print_matrix(\"\\na3 values\", self._a3)\n",
    "        return a3\n",
    "    \n",
    "    def da3_gen(self):\n",
    "        da3 = list()\n",
    "        for _i in range(n_out):\n",
    "            da3.append(d_sigmoid(self._a3[_i]))\n",
    "        da3 = np.array(da3)\n",
    "        self._da3 = da3.copy()\n",
    "        if DEBUG:\n",
    "            print_matrix(\"\\ndifferential of a3 values\", self._da3)\n",
    "        return da3\n",
    "    \n",
    "    def ca3_gen(self, index):\n",
    "        ca3 = list()\n",
    "        ans = answer(label[index])\n",
    "        for _i in range(len(ans)):\n",
    "            ca3.append(round(self._a3[_i] - ans[_i], 3))\n",
    "        ca3 = np.array(ca3)\n",
    "        self._ca3 = ca3.copy()\n",
    "        if DEBUG:\n",
    "            print_matrix(\"\\n∂C/∂a3 values\", self._ca3)\n",
    "        return ca3\n",
    "\n",
    "    def d3_gen(self):\n",
    "        d3 = list()\n",
    "        for _i in range(len(self._ca3)):\n",
    "            d3.append(round(self._da3[_i]*self._ca3[_i], 3))\n",
    "        d3 = np.array(d3)\n",
    "        self._d3 = d3.copy()\n",
    "        if DEBUG:\n",
    "            print_matrix(\"\\nδ3 values\", self._d3)\n",
    "        return d3\n",
    "    \n",
    "    def swd3_gen(self):\n",
    "        swd3 = np.dot(self._d3,self._weight_o)\n",
    "        for _i in range(len(swd3)):\n",
    "            swd3[_i] = round(swd3[_i], 3)\n",
    "        self._swd3 = swd3.copy()\n",
    "        if DEBUG:\n",
    "            print_matrix(\"\\nΣwδ3 values\",self._swd3)\n",
    "        return swd3\n",
    "\n",
    "    def d2_gen(self):\n",
    "        d2 = self._da2 * self._swd3\n",
    "        for _i in range(len(d2)):\n",
    "            d2[_i] = round(d2[_i], 3)\n",
    "        self._d2 = d2.copy()\n",
    "        if DEBUG:\n",
    "            print_matrix(\"\\nδ2 values\", self._d2)\n",
    "        return d2\n",
    "    \n",
    "    #Compute cost for each data\n",
    "    def cost(self, cl, index):\n",
    "        res = 0\n",
    "        ans = answer(cl[index])\n",
    "        for _i in range(n_out):\n",
    "            res = res + (ans[_i] - self._a3[_i])**2\n",
    "        cost = round(res/2, 3)\n",
    "        if DEBUG:\n",
    "            print(\"\\ncost\", cost)\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculate parameters for each data and save all\n",
    "def node_calc(node_weight, node_bias, output_weight, output_bias, index = None):\n",
    "    z2s = list()\n",
    "    a2s = list()\n",
    "    da2s = list()\n",
    "    z3s = list()\n",
    "    a3s = list()\n",
    "    da3s = list()\n",
    "    ca3s = list()\n",
    "    d3s = list()\n",
    "    swd3s = list()\n",
    "    d2s = list()\n",
    "    costs = list()\n",
    "\n",
    "    node = set_node_param(node_weight, node_bias, output_weight, output_bias)\n",
    "    if index is None:\n",
    "        for _i in range(n_data):\n",
    "            if DEBUG:\n",
    "                print()\n",
    "                print(\"Data #%d\"%(_i+1))\n",
    "            z2s.append(node.z2_gen(_i))\n",
    "            a2s.append(node.a2_gen())\n",
    "            da2s.append(node.da2_gen())\n",
    "            z3s.append(node.z3_gen())\n",
    "            a3s.append(node.a3_gen())\n",
    "            da3s.append(node.da3_gen())\n",
    "            ca3s.append(node.ca3_gen(_i))\n",
    "            d3s.append(node.d3_gen())\n",
    "            swd3s.append(node.swd3_gen())\n",
    "            d2s.append(node.d2_gen())\n",
    "            costs.append(node.cost(label, _i))\n",
    "        return (z2s, a2s, da2s, z3s, a3s, da3s, ca3s, d3s, swd3s, d2s, np.array(costs).sum())\n",
    "    elif type(index) == list:\n",
    "        if not CLEAN:\n",
    "            print(index)\n",
    "        for _i in index:\n",
    "            if DEBUG:\n",
    "                print(\"Data #%d\"%(_i+1))\n",
    "            z2s.append(node.z2_gen(_i))\n",
    "            a2s.append(node.a2_gen())\n",
    "            da2s.append(node.da2_gen())\n",
    "            z3s.append(node.z3_gen())\n",
    "            a3s.append(node.a3_gen())\n",
    "            da3s.append(node.da3_gen())\n",
    "            ca3s.append(node.ca3_gen(_i))\n",
    "            d3s.append(node.d3_gen())\n",
    "            swd3s.append(node.swd3_gen())\n",
    "            d2s.append(node.d2_gen())\n",
    "            costs.append(node.cost(label, _i))\n",
    "        return (z2s, a2s, da2s, z3s, a3s, da3s, ca3s, d3s, swd3s, d2s, np.array(costs).sum())\n",
    "    else:\n",
    "        z2 = node.z2_gen(index)\n",
    "        a2 = node.a2_gen()\n",
    "        da2 = node.da2_gen()\n",
    "        z3 = node.z3_gen()\n",
    "        a3 = node.a3_gen()\n",
    "        da3 = node.da3_gen()\n",
    "        ca3 = node.ca3_gen(index)\n",
    "        d3 = node.d3_gen()\n",
    "        swd3 = node.swd3_gen()\n",
    "        d2 = node.d2_gen() \n",
    "        cost = node.cost(label, index)\n",
    "        return (z2, a2, da2, z3, a3, da3, ca3, d3, swd3, d2, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(prev_l=None, back_prop=None):\n",
    "    set_param = param(learningrate=learningrate)\n",
    "    global INIT_FLAG\n",
    "    if prev_l is None and back_prop is None:\n",
    "        set_param.init()\n",
    "        INIT_FLAG = True\n",
    "        if not CLEAN:\n",
    "            print(\"Initialize node weight\")\n",
    "            print(\"Initialize node bias\")\n",
    "            print(\"Initialize output weight\")\n",
    "            print(\"Initialize output bias\")\n",
    "        node_weight = list()\n",
    "        for _i in range(n_node):\n",
    "            node_weight.append(set_param.update(d_width, d_height, prev_l, back_prop))\n",
    "        node_bias = set_param.update(n_node, weight=prev_l, backprop=back_prop)[0]\n",
    "        out_weight = set_param.update(n_node, n_out, prev_l, back_prop)\n",
    "        out_bias = set_param.update(n_out, weight=prev_l, backprop=back_prop)[0]\n",
    "    else:\n",
    "        if not CLEAN:\n",
    "            print(\"Updating node weight\")\n",
    "            print(\"Updating node bias\")\n",
    "            print(\"Updating output weight\")\n",
    "            print(\"Updating output bias\")\n",
    "        node_weight = list()\n",
    "        for _i in range(n_node):\n",
    "            node_weight.append(set_param.update(d_width, d_height, prev_l[0][_i], back_prop[0][_i]))\n",
    "        node_bias = set_param.update(n_node, weight=prev_l[1][np.newaxis], backprop=back_prop[1][np.newaxis])[0]\n",
    "        out_weight = set_param.update(n_node, n_out, prev_l[2], back_prop[2])\n",
    "        out_bias = set_param.update(n_out, weight=prev_l[3][np.newaxis], backprop=back_prop[3][np.newaxis])[0]\n",
    "        \n",
    "    \n",
    "    INIT_FLAG = False\n",
    "    if not CLEAN:\n",
    "        print_matrix(\"node weight values\", node_weight)\n",
    "        print_matrix(\"node bias values\", node_bias)\n",
    "        print_matrix(\"output weight values\", out_weight)\n",
    "        print_matrix(\"output bias values\", out_bias)\n",
    "    return (node_calc(node_weight, node_bias, out_weight, out_bias, TRAIN_INDEX), node_weight, node_bias, out_weight, out_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class backpropagation():\n",
    "    def node_weight(self, data, d2, index):\n",
    "        back_node_w = list()\n",
    "        for _index in range(len(index)):\n",
    "            weight = list()\n",
    "            for _i in range(n_node):\n",
    "                weight.append(data[index[_index]] * d2[_index][_i])\n",
    "            weight = np.array(weight)\n",
    "            back_node_w.append(weight)\n",
    "            if DEBUG:\n",
    "                print_matrix(\"backpropagation for #%d data\" %(_index+1), weight)\n",
    "        return back_node_w\n",
    "    \n",
    "    def node_bias(self, d2):\n",
    "        back_node_b = d2.copy()\n",
    "        return back_node_b\n",
    "    \n",
    "    def output_weight(self, a2, d3, index):\n",
    "        back_out_w = list()\n",
    "        for _index in range(len(index)):\n",
    "            _d3 = d3[_index]\n",
    "            _a2 = a2[_index]\n",
    "            weight = np.dot(np.transpose(_d3[np.newaxis]), _a2[np.newaxis])\n",
    "            weight = np.array(weight)\n",
    "            for _i in range(weight.shape[0]):\n",
    "                for _j in range(weight.shape[1]):\n",
    "                    weight[_i][_j] = round(weight[_i][_j], 3)\n",
    "            back_out_w.append(weight)\n",
    "            if DEBUG:\n",
    "                print_matrix(\"backpropagation output layer weight for #%d data\" %(_index+1),weight)\n",
    "        return back_out_w\n",
    "    \n",
    "    def output_bias(self, d3):\n",
    "        back_out_b = d3.copy()\n",
    "        return back_out_b\n",
    "\n",
    "    def sum_layer(self, x):\n",
    "        sum = 0\n",
    "        for _i in x:\n",
    "            sum = sum + _i\n",
    "        if np.array(x).ndim == 2:\n",
    "            for _i in range(len(sum)):\n",
    "                sum[_i] = round(sum[_i], 3)\n",
    "        return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(a2, d2, d3, index):\n",
    "    back = backpropagation()\n",
    "    back_n_w = back.node_weight(datas, d2, index)\n",
    "    back_n_b = back.node_bias(d2)\n",
    "    back_o_w = back.output_weight(a2, d3, index)\n",
    "    back_o_b = back.output_bias(d3)\n",
    "\n",
    "    sum_back_n_w = back.sum_layer(back_n_w)\n",
    "    sum_back_n_b = back.sum_layer(back_n_b)\n",
    "    sum_back_o_w = back.sum_layer(back_o_w)\n",
    "    sum_back_o_b = back.sum_layer(back_o_b)\n",
    "    if DEBUG:\n",
    "        print_matrix(\"∂CT/∂w values\", sum_back_n_w)\n",
    "        print_matrix(\"∂CT/∂b values\", sum_back_n_b)\n",
    "        print_matrix(\"output ∂CT/∂w values\", sum_back_o_w)\n",
    "        print_matrix(\"output ∂CT/∂b values\", sum_back_o_b)\n",
    "\n",
    "    return (sum_back_n_w, sum_back_n_b, sum_back_o_w, sum_back_o_b)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(forw_n_w, forw_n_b, forw_o_w, forw_o_b, index):\n",
    "    r_cnt = 0\n",
    "    w_cnt = 0\n",
    "    \n",
    "    for _index in index:\n",
    "        z2, a2, da2, z3, a3, da3, ca3, d3, swd3, d2, cost = node_calc(forw_n_w, forw_n_b, forw_o_w, forw_o_b, _index)\n",
    "        if not CLEAN:\n",
    "            print_matrix(\"Data #%d\\nPredict output\"%(_index + 1),a3)\n",
    "        if a3[0] > a3[1]:\n",
    "            predict = 0\n",
    "            if not CLEAN:\n",
    "                print(\"Predict: 0\")\n",
    "        else:\n",
    "            predict = 1\n",
    "            if not CLEAN:\n",
    "                print(\"Predict: 1\")\n",
    "        if not CLEAN:\n",
    "            print(\"Label: \",label[_index])\n",
    "        if predict == label[_index]:\n",
    "            if not CLEAN:\n",
    "                print(\"Right\")\n",
    "            r_cnt = r_cnt+1\n",
    "        else:\n",
    "            if not CLEAN:\n",
    "                print(\"Wrong\")\n",
    "            w_cnt = w_cnt+1\n",
    "        cost = round(cost, 3)\n",
    "    accuracy = round(r_cnt/(r_cnt+w_cnt), 3)\n",
    "    if index == TEST_INDEX:\n",
    "        print(\"Cost: %.3f\" %(cost))\n",
    "    print(\"Accuracy: %.3f\\n\\n\"%(accuracy))\n",
    "\n",
    "    return accuracy, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network():\n",
    "    costs = list()\n",
    "    accs = list()\n",
    "    prev = None\n",
    "    backprop = None\n",
    "    for _i in range(epoch):\n",
    "        print(\"#%d epoch\"%(_i+1))\n",
    "        (z2, a2, da2, z3, a3, da3, ca3, d3, swd3, d2, cost), forw_n_w, forw_n_b, forw_o_w, forw_o_b = forward(prev, backprop)\n",
    "        costs.append(round(cost, 3))        \n",
    "        back_n_w, back_n_b, back_o_w, back_o_b = backward(a2, d2, d3, TRAIN_INDEX)\n",
    "        prev = (forw_n_w, forw_n_b, forw_o_w, forw_o_b)\n",
    "        backprop = (back_n_w, back_n_b, back_o_w, back_o_b)\n",
    "        if not CLEAN:\n",
    "            print()\n",
    "        print(\"Cost: %.3f\" %(cost))\n",
    "        acc = verify(forw_n_w, forw_n_b, forw_o_w, forw_o_b, TRAIN_INDEX)[0]\n",
    "        accs.append(acc)\n",
    "    return (z2, a2, da2, z3, a3, da3, ca3, d3, swd3, d2, costs, forw_n_w, forw_n_b, forw_o_w, forw_o_b, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(forw_n_w, forw_n_b, forw_o_w, forw_o_b):\n",
    "    accs = list()\n",
    "    for _i in range(epoch):\n",
    "        acc = verify(forw_n_w, forw_n_b, forw_o_w, forw_o_b, TEST_INDEX)[0]\n",
    "        accs.append(acc)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning():\n",
    "    z2, a2, da2, z3, a3, da3, ca3, d3, swd3, d2, train_costs, forw_n_w, forw_n_b, forw_o_w, forw_o_b, train_accs = network()\n",
    "    print_matrix(\"Hidden layer weight\",forw_n_w)\n",
    "    print_matrix(\"Hidden layer bias\", forw_n_b)\n",
    "    print_matrix(\"Output layer weight\", forw_o_w)\n",
    "    print_matrix(\"Output layer bias\", forw_o_b)\n",
    "    print(\"\\nFinal Cost:\", train_costs[epoch-1])\n",
    "    print(\"\\nTest\")\n",
    "    test_accs = test(forw_n_w, forw_n_b, forw_o_w, forw_o_b)\n",
    "    return (train_accs, train_costs, test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "def graph(train_accs, train_costs, test_accs):\n",
    "    x = range(epoch)\n",
    "    y = [train_accs, train_costs, test_accs]\n",
    "    y[1] = preprocessing.normalize(np.array(y[1])[np.newaxis])\n",
    "    y[1] = y[1][0]\n",
    "    labels = [\"Trian accuarcy\", \"Train cost\", \"Test accuracy\"]\n",
    "    fig = plt.figure()\n",
    "    fig.set_facecolor('white')\n",
    "    for _i in range(len(labels)):\n",
    "        sns.lineplot(x=x, y=y[_i], label=labels[_i])\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 epoch\n",
      "Cost: 19.197\n",
      "Accuracy: 0.517\n",
      "\n",
      "\n",
      "#2 epoch\n",
      "Cost: 15.375\n",
      "Accuracy: 0.517\n",
      "\n",
      "\n",
      "#3 epoch\n",
      "Cost: 14.665\n",
      "Accuracy: 0.552\n",
      "\n",
      "\n",
      "#4 epoch\n",
      "Cost: 14.067\n",
      "Accuracy: 0.552\n",
      "\n",
      "\n",
      "#5 epoch\n",
      "Cost: 13.251\n",
      "Accuracy: 0.655\n",
      "\n",
      "\n",
      "#6 epoch\n",
      "Cost: 12.141\n",
      "Accuracy: 0.793\n",
      "\n",
      "\n",
      "#7 epoch\n",
      "Cost: 10.654\n",
      "Accuracy: 0.793\n",
      "\n",
      "\n",
      "#8 epoch\n",
      "Cost: 9.120\n",
      "Accuracy: 0.879\n",
      "\n",
      "\n",
      "#9 epoch\n",
      "Cost: 7.635\n",
      "Accuracy: 0.879\n",
      "\n",
      "\n",
      "#10 epoch\n",
      "Cost: 6.358\n",
      "Accuracy: 0.931\n",
      "\n",
      "\n",
      "#11 epoch\n",
      "Cost: 5.296\n",
      "Accuracy: 0.966\n",
      "\n",
      "\n",
      "#12 epoch\n",
      "Cost: 4.446\n",
      "Accuracy: 0.966\n",
      "\n",
      "\n",
      "#13 epoch\n",
      "Cost: 3.787\n",
      "Accuracy: 0.966\n",
      "\n",
      "\n",
      "#14 epoch\n",
      "Cost: 3.292\n",
      "Accuracy: 0.966\n",
      "\n",
      "\n",
      "#15 epoch\n",
      "Cost: 2.916\n",
      "Accuracy: 0.966\n",
      "\n",
      "\n",
      "#16 epoch\n",
      "Cost: 2.618\n",
      "Accuracy: 0.966\n",
      "\n",
      "\n",
      "#17 epoch\n",
      "Cost: 2.377\n",
      "Accuracy: 0.966\n",
      "\n",
      "\n",
      "#18 epoch\n",
      "Cost: 2.184\n",
      "Accuracy: 0.966\n",
      "\n",
      "\n",
      "#19 epoch\n",
      "Cost: 2.022\n",
      "Accuracy: 0.966\n",
      "\n",
      "\n",
      "#20 epoch\n",
      "Cost: 1.878\n",
      "Accuracy: 0.966\n",
      "\n",
      "\n",
      "#21 epoch\n",
      "Cost: 1.757\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#22 epoch\n",
      "Cost: 1.649\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#23 epoch\n",
      "Cost: 1.551\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#24 epoch\n",
      "Cost: 1.465\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#25 epoch\n",
      "Cost: 1.390\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#26 epoch\n",
      "Cost: 1.319\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#27 epoch\n",
      "Cost: 1.256\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#28 epoch\n",
      "Cost: 1.196\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#29 epoch\n",
      "Cost: 1.147\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#30 epoch\n",
      "Cost: 1.088\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#31 epoch\n",
      "Cost: 1.053\n",
      "Accuracy: 0.983\n",
      "\n",
      "\n",
      "#32 epoch\n",
      "Cost: 1.003\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#33 epoch\n",
      "Cost: 0.962\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#34 epoch\n",
      "Cost: 0.924\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#35 epoch\n",
      "Cost: 0.885\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#36 epoch\n",
      "Cost: 0.853\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#37 epoch\n",
      "Cost: 0.819\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#38 epoch\n",
      "Cost: 0.795\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#39 epoch\n",
      "Cost: 0.765\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#40 epoch\n",
      "Cost: 0.740\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#41 epoch\n",
      "Cost: 0.717\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#42 epoch\n",
      "Cost: 0.693\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#43 epoch\n",
      "Cost: 0.671\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#44 epoch\n",
      "Cost: 0.649\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#45 epoch\n",
      "Cost: 0.629\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#46 epoch\n",
      "Cost: 0.611\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#47 epoch\n",
      "Cost: 0.592\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#48 epoch\n",
      "Cost: 0.577\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#49 epoch\n",
      "Cost: 0.561\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "#50 epoch\n",
      "Cost: 0.541\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "\n",
      "Hidden layer weight\n",
      "1 [[ 0.697 -0.921 -1.092]\n",
      " [-1.939  1.687 -0.566]\n",
      " [-1.581  2.792 -1.57 ]\n",
      " [ 0.245 -0.486 -0.011]]\n",
      "2 [[ 1.037 -0.033 -3.198]\n",
      " [ 0.032  0.694  1.35 ]\n",
      " [ 0.607 -0.575 -0.725]\n",
      " [ 0.464  2.127  0.036]]\n",
      "3 [[-0.708  2.275 -2.129]\n",
      " [-0.132  1.319  0.033]\n",
      " [-1.723  0.693 -1.531]\n",
      " [-2.097  2.444 -0.82 ]]\n",
      "\n",
      "Hidden layer bias\n",
      "1 0.787\n",
      "2 -0.643\n",
      "3 -0.911\n",
      "\n",
      "Output layer weight\n",
      "1 [-2.965 -0.077 -3.356]\n",
      "2 [ 2.885 -0.306  3.645]\n",
      "\n",
      "Output layer bias\n",
      "1 2.547\n",
      "2 -2.354\n",
      "\n",
      "Final Cost: 0.541\n",
      "\n",
      "Test\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n",
      "Cost: 0.021\n",
      "Accuracy: 1.000\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accs, train_costs, test_accs = learning()\n",
    "graph(train_accs, train_costs, test_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
